<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>WebCrawlerProject-Lecture2</title>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="shortcut icon" type="image/jpg" href="/PythonCourseNetIT-Slides/favicon.png"/>

    <!-- css & themes include -->
    <link rel="stylesheet" href="/PythonCourseNetIT-Slides/lib/reveal.js/css/reveal.css">
    <link rel="stylesheet" href="/PythonCourseNetIT-Slides/outfit/css/themes/light.css" id="theme">
    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match( /print-pdf/gi ) ? '/PythonCourseNetIT-Slides/outfit/css/print.css' : '/PythonCourseNetIT-Slides/lib/reveal.js/css/print/paper.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
    <!-- CUSTOM -->
    <base target="_blank">
</head>
<body>
    <div class="reveal default center" data-transition-speed="default" data-background-transition="default">
        <div class="top_links">
            <a class="home_link" href="/PythonCourseNetIT-Slides/pages/agenda/agenda.html" target="_top"></a>
            <span class="help_link"><i class="fa fa-question"></i></span>
            <div class="help_text">
                <div class="note">Keyboard shortcuts:</div>
                <div><span>N/Спейс</span><span>Next Slide</span></div>
                <div><span>P</span><span>Previous Slide</span></div>
                <div><span>O</span><span>Slides Overview</span></div>
                <div><span>ctrl+left click</span><span>Zoom Element</span></div>
                <div class="print-howto"><br>If you want print version => add '<code>?print-pdf</code>' <br> at the end of slides URL (remove '#' fragment) and then print. <br>
                Like: https://wwwcourses.github.io/...CourseIntro.html?print-pdf </div>
            </div>
        </div>
        <div class="footer theme_switch">
            <a href="#" onclick="document.getElementById('theme').setAttribute('href','/PythonCourseNetIT-Slides/outfit/css/themes/dark.css'); return false;">Dark</a>
            <a href="#" onclick="document.getElementById('theme').setAttribute('href','/PythonCourseNetIT-Slides/outfit/css/themes/light.css'); return false;">Light</a>
            <a href="#" onclick="document.getElementById('theme').setAttribute('href','/PythonCourseNetIT-Slides/outfit/css/themes/projector.css'); return false;">Projector</a>
        </div>
        <div class="slides">
<!--
########################################################
##################### SLIDES START #####################
########################################################
-->

<section class="main-section-title"><h1>WebCrawlerProject-Lecture2</h1></section>
<section data-transition="zoom">
    <section class="copyright" data-transition="zoom">
        <div class="note">
            <p>Created for</p>
        </div>
        <div class="company">
            <a href="https://softwareacademy.bg/">
            <img style="height:80%" src="/PythonCourseNetIT-Slides/outfit/images/logos/software-web@4x.png" alt="software-web@4x.png">
            </a>
        </div>
        <div class="author">
            <span class="note"><a href="https://www.linkedin.com/in/ivapopova/">Iva E. Popova</a>, 2022-2023,</span>
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"></a>
            <!-- <i class="fa fa-linkedin"></i> -->
        </div>
    </section>
</section>


<section data-min="50" class="main-section-title"><h1>Web Scraping with BeautifulSoup - Overview</h1></section>
<section class="sub-sections"><h2>Web Scraping with BeautifulSoup - Overview</h2>
    <section><h3>What is BeautifulSoup?</h3>
        <dl class="fa">
            <dt>Beautiful soup is one of the most widely-used Python libraries for web scraping.</dt>
            <dt>It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree.</dt>
            <dt>Reference:</dt>
            <dd><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup Documentation</a></dd>
            <dt>Installation:</dt>
            <pre><code rel="Python" class="python">
                pip install beautifulsoup4
            </code></pre>
        </dl>
    </section>
    <section><h3>Popular BeautifulSoup Use Cases</h3>
        <dl class="fa">
            <dt>Data analysis projects that require quick and easy access to web data.</dt>
            <dt>Automating the collection of information from multiple pages of a website for research or market analysis.</dt>
            <dt>Scraping data from HTML tables into CSV files or databases for further processing.</dt>
            <dt>Monitoring changes in website content over time for competitive analysis.</dt>
        </dl>
    </section>
    <section><h3>How BeautifulSoup Works?</h3>
        <dl class="fa">
            <dt>BeautifulSoup transforms a complex HTML document into a complex tree of Python objects. The BeautifulSoup object itself represents the document as a whole.</dt>
            <dt>To parse a document, pass it into the BeautifulSoup constructor. You can use a variety of parsers, like html.parser or lxml, depending on your needs.</dt>
            <dt>Example:</dt>
            <dd><code>
                from bs4 import BeautifulSoup<br>
                soup = BeautifulSoup(html_doc, 'html.parser')
            </code></dd>
        </dl>
        <img src="./images/BeautifulSoupParsingExample.svg.png" alt="BeautifulSoupParsingExample.svg.png">
    </section>
</section>
<section><h2>BeautifulSoup Methods</h2>
    <section><h3>find() and find_all()</h3>
        <dl class="fa">
            <dt><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find"><code>find()</code></a> searches for the first tag that matches a given criterion.</dt>
            <dt><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all"><code>find_all()</code></a> retrieves a list of tags that match the given criteria.</dt>
        </dl>
        <pre><code rel="Python" class="python" style="min-height: 70vh;">
            from bs4 import BeautifulSoup

            html = &quot;&quot;&quot;
            &lt;html&gt;
                &lt;body&gt;
                    &lt;p&gt;Hello World&lt;/p&gt;
                    &lt;p&gt;Just a paragraph&lt;/p&gt;
                    &lt;p&gt;Yet &lt;b&gt;another&lt;/b&gt; paragpraph&lt;/p&gt;
                &lt;/body&gt;
            &lt;/html&gt;
            &quot;&quot;&quot;

            soup = BeautifulSoup(html, &#39;html.parser&#39;)

            # get first p element:
            first_p =soup.find(&#39;p&#39;)

            # get all p elements:
            all_p =soup.find_all(&#39;p&#39;)

            print(first_p)
            print(all_p)

        </code></pre>
    </section>
    <section><h3>Find elements by html attributes</h3>
        <dl class="fa" style="min-width:80vw">
            <dt>You can pass relevant attribute names and values as keyword arguments to the find() and find_all() methods</dt>
            <dd>Note, that 'class' is a reserved word in Python, so for class attribute we must use 'class_'.</dd>
            <pre><code rel="Python" class="python" style="min-height: 80vh;">
                from bs4 import BeautifulSoup

                html = &quot;&quot;&quot;
                &lt;html&gt;
                    &lt;body&gt;
                        &lt;h1 class=&quot;red&quot;&gt;Page heading&lt;/h1&gt;
                        &lt;p class=&quot;message red&quot;&gt;Hello World&lt;/p&gt;
                        &lt;p&gt;Just a paragraph&lt;/p&gt;
                        &lt;p id=&quot;p3&quot;&gt;Yet another paragpraph&lt;/p&gt;
                    &lt;/body&gt;
                &lt;/html&gt;
                &quot;&quot;&quot;

                soup = BeautifulSoup(html, &#39;html.parser&#39;)

                # get all elements which have class &quot;red&quot;
                all_red =soup.find_all(class_=&quot;red&quot;)

                # get all p elements which have class &quot;red&quot;
                all_red_p =soup.find_all(&#39;p&#39;, class_=&quot;red&quot;)

                # get element with id=&quot;p3&quot;:
                p3 =soup.find(id=&#39;p3&#39;)

                print(all_red)
                print(all_red_p)
                print(p3)
            </code></pre>
        </dl>
    </section>
    <section><h3>Find elements by CSS selectors</h3>
        <dl class="fa">
            <dt>You can use CSS selectors to find elements using css property or he shortcut methods:</dt>
            <dd><code>tag.css.select_one()</code> or <code>tag.select_one()</code> - gets the first element matching the selector</dd>
            <dd><code>tag.css.select()</code> or <code>tag.select()</code> - gets all elements matching the selector</dd>
            <dt>Reference: <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors-through-the-css-property">CSS selectors through the .css property</a></dt>
            <pre><code rel="Python" class="python" style="min-height: 70vh;">
                from bs4 import BeautifulSoup

                html = &quot;&quot;&quot;
                &lt;html&gt;
                    &lt;body&gt;
                        &lt;h1 class=&quot;red&quot;&gt;Page heading&lt;/h1&gt;
                        &lt;p class=&quot;message red&quot;&gt;Hello World&lt;/p&gt;
                        &lt;p&gt;Just a paragraph&lt;/p&gt;
                        &lt;p id=&quot;p3&quot;&gt;Yet another paragpraph&lt;/p&gt;
                    &lt;/body&gt;
                &lt;/html&gt;
                &quot;&quot;&quot;

                soup = BeautifulSoup(html, &#39;html.parser&#39;)

                # get all elements which have class &quot;red&quot; using CSS selector:
                all_red =soup.select(&quot;.red&quot;)

                # get all p elements which have class &quot;red&quot; using CSS selector:
                all_red_p =soup.select(&quot;p.red&quot;)

                # get element with id=&quot;p3&quot; using CSS selector:
                p3 =soup.select_one(&quot;#p3&quot;)

                print(all_red)
                print(all_red_p)
                print(p3)
            </code></pre>
        </dl>
    </section>
    <section><h3>Find elements by CSS selectors - example</h3>
        <pre><code rel="Python" class="python" style="min-height: 92vh;">
            from bs4 import BeautifulSoup

            html = &quot;&quot;&quot;
            &lt;html&gt;
                &lt;body&gt;
                    &lt;ul class=&quot;menu&quot;&gt;
                        &lt;li&gt;&lt;a href=&quot;https://somesite.com/page1&quot;&gt;page1&lt;/a&gt;&lt;/li&gt;
                        &lt;li&gt;&lt;a href=&quot;https://somesite.com/page2&quot;&gt;page2&lt;/a&gt;&lt;/li&gt;
                    &lt;/ul&gt;
                    &lt;hr&gt;
                    &lt;ul class=&quot;ads&quot;&gt;
                        &lt;li&gt;&lt;a href=&quot;https://somesite.com/add1&quot;&gt;add1&lt;/a&gt;&lt;/li&gt;
                        &lt;li&gt;&lt;a href=&quot;https://somesite.com/add2&quot;&gt;add2&lt;/a&gt;&lt;/li&gt;
                    &lt;/ul&gt;
                &lt;/body&gt;
            &lt;/html&gt;
            &quot;&quot;&quot;

            soup = BeautifulSoup(html, &#39;html.parser&#39;)

            # get all links (a elements) which are in &lt;ul class=&quot;menu&quot;&gt; using desendant combinator:
            menu_links =soup.select(&quot;.menu a&quot;)

            print(menu_links)
        </code></pre>
    </section>
    <section><h3>Extracting Text and HTML Content in BeautifulSoup</h3>
        <dl class="fa">
            <dt><code>.text</code> attribute or <code>.get_text()</code> method: extracts all text content inside an element.</dt>
            <dt><code>tag.string</code>: extracts text from element which have only text content as a child. If element contains not only text, but other HTML elements <code>tag.string</code> return <code>None</code>.</dt>
            <dt><code>tag.decode_contents()</code>: extract the inner HTML from an element</dt>
        </dl>
        <pre><code rel="Python" class="python" style="min-height: 70vh;">
            from bs4 import BeautifulSoup

            html = &quot;&quot;&quot;
            &lt;body&gt;
                &lt;p&gt;Hello &lt;b&gt;world&lt;/b&gt;!&lt;/p&gt;
            &lt;/body&gt;
            &quot;&quot;&quot;

            soup = BeautifulSoup(html, &#39;html.parser&#39;)
            p = soup.find(&quot;p&quot;)
            b = soup.find(&quot;b&quot;)

            # Getting text with text property:
            print( p.text )     #Hello world!

            # Getting text with .get_text()
            print( p.get_text() )   #Hello world!

            # Getting text content with string proprty
            print( p.string ) #None
            print( b.string ) #world

            # Getting inner HTML with .decode_contents()
            print(p.decode_contents()) #Hello &lt;b&gt;world&lt;/b&gt;!
        </code></pre>
    </section>
    <section><h3>Getting Attribute Values</h3>
        <dl class="fa">
            <dt>BeautifulSoup stores HTML attributes and their vaules in a dictionary, which can be accessed by <code>tag.attrs</code> property</dt>
            <dt>To get the value of an attribute, you can access it by <code>tag['key']</code> or by <code>tag.get(key)</code> method.</dt>
            <pre><code rel="Python" class="python" style="min-height: 66vh;">
                from bs4 import BeautifulSoup

                html = &quot;&quot;&quot;
                &lt;body&gt;
                    &lt;a href=&quot;http://example.com&quot; title=&quot;Go to example site&quot;&gt;example&lt;/a&gt;
                &lt;/body&gt;
                &quot;&quot;&quot;

                soup = BeautifulSoup(html, &#39;html.parser&#39;)

                a = soup.find(&#39;a&#39;)
                # get the value of href attribute:
                print( a[&#39;href&#39;])   #http://example.com
                print( a.get(&#39;href&#39;)) #http://example.com

                # get all HTML attributes:
                print( a.attrs ) #{&#39;href&#39;: &#39;http://example.com&#39;, &#39;title&#39;: &#39;Go to example site&#39;}
            </code></pre>
        </dl>
    </section>
    <section><h3>Navigating the Tree</h3>
        <dl class="fa">
            <dt>BeautifulSoup allows you to navigate the parse tree using tag names and properties like <code>.contents</code>, <code>.parent</code>, and <code>.next_sibling</code>.</dt>
            <dt>Reference: <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree">Navigating the tree</a></dt>
            <pre><code rel="Python" class="python" style="min-height: 90vh;">
                from bs4 import BeautifulSoup

                html = &quot;&quot;&quot;
                &lt;body&gt;
                    &lt;div&gt;
                        &lt;h3&gt;Product 1 title&lt;/h3&gt;
                        &lt;a href=&quot;/products/1&quot;&gt;view product1 page&lt;/a&gt;
                    &lt;/div&gt;
                    &lt;div&gt;
                        &lt;h3&gt;Product 2 title&lt;/h3&gt;
                        &lt;a href=&quot;/products/2&quot;&gt;view product2 page&lt;/a&gt;
                    &lt;/div&gt;
                    &lt;a href=&quot;https://somesite.com/add1&quot;&gt;add1&lt;/a&gt;
                &lt;/body&gt;
                &quot;&quot;&quot;

                # Task: get links and h3 heading for all products by selecting a tag which href starts with &quot;/products&quot;
                soup = BeautifulSoup(html, &#39;html.parser&#39;)

                products_links = soup.select(&#39;a[href^=&quot;/products&quot;]&#39;)

                for link in products_links:
                    print(link)
                    # get h3 from link&#39;s parent div:
                    h3 = link.parent.find(&#39;h3&#39;)
                    print(h3)

                # &lt;a href=&quot;/products/1&quot;&gt;view product1 page&lt;/a&gt;
                # &lt;h3&gt;Product 1 title&lt;/h3&gt;
                # &lt;a href=&quot;/products/2&quot;&gt;view product2 page&lt;/a&gt;
                # &lt;h3&gt;Product 2 title&lt;/h3&gt;
            </code></pre>
        </dl>
    </section>
</section>
<section class="sub-sections"><h2>Live Demos</h2>
    <section><h3>Countries of the World: A Simple Example</h3>
        <dl class="fa" style="min-width:80vw">
            <dt>Let's extract information about each country given into this page:<a href="https://www.scrapethissite.com/pages/simple/">Countries of the World: A Simple Example</a></dt>
        </dl>
    </section>
</section>




<section class="disclaimer end-slide"></section>
<!--
########################################################
##################### SLIDES END   #####################
########################################################
-->
        </div>
    </div>
    <!-- Custom processing -->
    <script src="/PythonCourseNetIT-Slides/outfit/js/slides.js"></script>
    <!-- external scripts -->
    <script src="/PythonCourseNetIT-Slides/lib/reveal.js/lib/js/head.min.js"></script>
    <script src="/PythonCourseNetIT-Slides/lib/reveal.js/js/reveal.js"></script>
     <!-- init reveal -->
    <script>
        // Full list of configuration options available at:
        // https://github.com/hakimel/reveal.js#configuration
        var highlightjsTabSize = '  ';
        Reveal.initialize({
            controls: true,
            progress: true,
            slideNumber: 'c/t',
            keyboard: true,
            history: true,
            center: true,
            width: 1920,
            height: 1080,
            // Bounds for smallest/largest possible scale to apply to content
            // minScale: .5,
            maxScale: 1,
            // slide transition
            transition: 'concave', // none/fade/slide/convex/concave/zoom
            // Factor of the display size that should remain empty around the content
            margin: 0.1,
            // shift+left click to zoom in/out element
            zoomKey: 'ctrl',
            // theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
            // transition: Reveal.getQueryHash().transition || 'default'
            // Optional reveal.js plugins
            dependencies: [
                { src: '/PythonCourseNetIT-Slides/lib/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
                { src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.configure({tabReplace: highlightjsTabSize}); hljs.initHighlightingOnLoad(); } },
                { src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/zoom-js/zoom.js', async: true },
                { src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/notes/notes.js', async: true }
            ]
        });
    </script>
</body>
</html>
