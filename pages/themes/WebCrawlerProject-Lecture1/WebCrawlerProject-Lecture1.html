<!doctype html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>WebCrawlerProject-Lecture1</title>
	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

	<link rel="shortcut icon" type="image/jpg" href="/PythonCourseNetIT-Slides/favicon.png"/>

	<!-- css & themes include -->
	<link rel="stylesheet" href="/PythonCourseNetIT-Slides/lib/reveal.js/css/reveal.css">
	<link rel="stylesheet" href="/PythonCourseNetIT-Slides/outfit/css/themes/light.css" id="theme">
	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement( 'link' );
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match( /print-pdf/gi ) ? '/PythonCourseNetIT-Slides/outfit/css/print.css' : '/PythonCourseNetIT-Slides/lib/reveal.js/css/print/paper.css';
		document.getElementsByTagName( 'head' )[0].appendChild( link );
	</script>
	<!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
	<!-- CUSTOM -->
	<base target="_blank">
</head>
<body>
	<div class="reveal default center" data-transition-speed="default" data-background-transition="default">
		<div class="top_links">
			<a class="home_link" href="/PythonCourseNetIT-Slides/pages/agenda/agenda.html" target="_top"></a>
			<span class="help_link"><i class="fa fa-question"></i></span>
			<div class="help_text">
				<div class="note">Keyboard shortcuts:</div>
				<div><span>N/Спейс</span><span>Next Slide</span></div>
				<div><span>P</span><span>Previous Slide</span></div>
				<div><span>O</span><span>Slides Overview</span></div>
				<div><span>ctrl+left click</span><span>Zoom Element</span></div>
				<div class="print-howto"><br>If you want print version => add '<code>?print-pdf</code>' <br> at the end of slides URL (remove '#' fragment) and then print. <br>
				Like: https://wwwcourses.github.io/...CourseIntro.html?print-pdf </div>
			</div>
		</div>
		<div class="footer theme_switch">
			<a href="#" onclick="document.getElementById('theme').setAttribute('href','/PythonCourseNetIT-Slides/outfit/css/themes/dark.css'); return false;">Dark</a>
			<a href="#" onclick="document.getElementById('theme').setAttribute('href','/PythonCourseNetIT-Slides/outfit/css/themes/light.css'); return false;">Light</a>
			<a href="#" onclick="document.getElementById('theme').setAttribute('href','/PythonCourseNetIT-Slides/outfit/css/themes/projector.css'); return false;">Projector</a>
		</div>
		<div class="slides">
<!--
########################################################
##################### SLIDES START #####################
########################################################
-->

<section><h1>WebCrawlerProject-Lecture1</h1></section>
<section data-transition="zoom">
	<!-- linkedin badge -->
	<section class="copyright" data-transition="zoom">
		<div class="note">
			<p>Created for</p>
		</div>
		<div class="company">
			<a href="https://softwareacademy.bg//програмиране-с-python-2/" title="click for bigger image">
			<img style="height:80%" src="/PythonCourseNetIT-Slides/outfit/images/logos/software-web@4x.png" alt="software-web@4x.png">
			</a>
		</div>
	</section>
	<!-- <section class="copyright" data-transition="zoom" style="margin-top: -2em;">
		<div class="company">
			 <div class="LI-profile-badge"  data-version="v1" data-size="large" data-locale="en_US" data-type="vertical" data-theme="dark" data-vanity="ivapopova"><a class="LI-simple-link" href='https://bg.linkedin.com/in/ivapopova?trk=profile-badge'>Iva E. Popova on LinkedIn</a></div>
		</div>
	</section> -->
</section>

<section data-min="50"><h1>WebCrawling - Overview</h1></section>
<section><h2>WebCrawling - Overview</h2>
	<section><h3>What is Web Crawling?</h3>
		<dl class="fa">
			<dt>A Web crawler (aka <i>spider</i>, <i>internet bot</i>), is a program that systematically browses the World Wide Web, typically operated by search engines for the purpose of Web indexing (web spidering)</dt>
			<dt>WebCrawling is a part (subsystem) of <i>WebScraping</i>, <i>Web Data Mining/Extraction</i> software systems.</dt>
			<dt>Reference:</dt>
			<dd><a href="https://en.wikipedia.org/wiki/Web_crawler">Web Crawler @wikipedia</a></dd>
			<dd><a href="https://en.wikipedia.org/wiki/Web_scraping">Web Scraping @wikipedia</a></dd>
		</dl>
	</section>
	<section><h3>How a WebCrawler Works?</h3>
		<dl class="fa">
			<dt>A web crawler starts with a list of URLs to visit, called the seed.</dt>
			<dt>For each URL, the crawler finds links in the HTML, filters those links based on some criteria and adds the new links to a queue.</dt>
			<dt>All the HTML or some specific information is extracted to be processed by a different pipeline.</dt>
		</dl>
		<a href="./images/WebCrawlerArchitecture.svg.png"><img src="./images/WebCrawlerArchitecture.svg.png" alt="WebCrawlerArchitecture.svg.png"></a>
	</section>
	<section><h3>Popular web crawler use cases</h3>
		<dl class="fa">
			<dt>Search engines (Googlebot, Bingbot, Yandex Bot…) collect all the HTML for a significant part of the Web. This data is indexed to make it searchable.</dt>
			<dt>SEO analytics tools on top of collecting the HTML also collect metadata like the response time, response status to detect broken pages and the links between different domains to collect backlinks.</dt>
			<dt>Price monitoring tools crawl e-commerce websites to find product pages and extract metadata, notably the price. Product pages are then periodically revisited.</dt>
			<dt>Social Network data extraction, Sentiment Analyses, ...</dt>
		</dl>
	</section>
	<section><h3>Web Crawling Legal/Ethical Concerns</h3>
		<dl class="fa">
			<dt>Crawlers consume resources on visited systems and often visit sites without approval.</dt>
			<dt>Issues of schedule, load, and "politeness" come into play when large collections of pages are accessed.</dt>
			<dt>Mechanisms exist for public sites not wishing to be crawled to make this known to the crawling agent. For example, including a <code>robots.txt</code> file can request bots to index only parts of a website, or nothing at all.</dt>

		</dl>
	</section>
	<section><h3>robots.txt - example</h3>
		<pre><code rel="http://example.com/robots.txt" class="bash">
			# The user agent named Googlebot is not allowed to crawl any URL that starts with http://example.com/search/.
			User-agent: Googlebot
			Disallow: /search/

			# All other user agents are allowed to crawl the entire site.
			User-agent: *
			Allow: /
		</code></pre>
		<dl class="fa">
			<dt>Reference: <a href="https://developers.google.com/search/docs/advanced/robots/create-robots-txt#create_rules">robots.txt syntax</a></dt>
		</dl>
	</section>
</section>

<section data-min="50"><h1>Web Crawling with Python</h1></section>
<section><h2>Web Crawling with Python</h2>
	<section><h3>The Process</h3>
		<dl class="fa">
			<dt>Visual inspection: Figure out what to extract</dt>
			<dd>Tools: Browser's Dev Tools, like <a href="https://developer.chrome.com/docs/devtools/overview/">Chrome DevTools</a></dd>
			<dt>Make an HTTP request to the webpage and parse it</dt>
			<dd>Tools: python library like: <a href="https://docs.python-requests.org/en/master/">Requests</a>, <a href="https://docs.python.org/2/library/urllib.html#module-urllib">urllib</a></dd>
			<dt>Parse the HTML to get the relevant data</dt>
			<dd><a href="https://pypi.org/project/beautifulsoup4/">beautifulsoup4</a></dd>
		</dl>
	</section>
	<section><h3>Using Chrome DevTools to inspect a WebPage</h3>
		<dl class="fa">
			<dt>Live Demo on:</dt>
			<dd><a href="https://www.rottentomatoes.com/browse/in-theaters/">https://www.rottentomatoes.com/browse/in-theaters/</a></dd>
			<dd><a href="https://bnr.bg/lyubopitno/list">https://bnr.bg/lyubopitno/list</a></dd>
			<dd><a href="https://www.jobs.bg/front_job_search.php?add_sh=1&from_hp=1&keywords%5B%5D=python">https://www.jobs.bg/front_job_search.php</a></dd>
			<dd><a href="https://www.jarcomputers.com/Laptopi_cat_2.html?ref=c_1">https://www.jarcomputers.com/Laptopi_cat_2.html?ref=c_1</a></dd>
		</dl>
	</section>
	<section><h3>Using <code>Requests</code> to get page content</h3>
		<dl class="fa">
			<dt>Reference: <a href="https://docs.python-requests.org/en/latest/">Requests: HTTP for Humans</a></dt>
			<dt>Live Demo</dt>
			<dd>get HTML content of a web site</dd>
			<dd>Use JSON APIs: <a href="https://api.chucknorris.io/">Chuck Norris Jokes</a> or <a href="https://mixedanalytics.com/blog/list-actually-free-open-no-auth-needed-apis/">List of Free and Open Public APIs</a></dd>
		</dl>
	</section>
</section>

<section class="disclaimer" data-background="/PythonCourseNetIT-Slides/outfit/images/for_slides/the_end_on_sand.jpg"></section>
<!--
########################################################
##################### SLIDES END   #####################
########################################################
-->
		</div>
	</div>
	<!-- Custom processing -->
	<script src="/PythonCourseNetIT-Slides/outfit/js/slides.js"></script>
	<!-- external scripts -->
	<script src="/PythonCourseNetIT-Slides/lib/reveal.js/lib/js/head.min.js"></script>
	<script src="/PythonCourseNetIT-Slides/lib/reveal.js/js/reveal.js"></script>
	 <!-- init reveal -->
	<script>
		// Full list of configuration options available at:
		// https://github.com/hakimel/reveal.js#configuration
		var highlightjsTabSize = '  ';
		Reveal.initialize({
			controls: true,
			progress: true,
			slideNumber: 'c/t',
			keyboard: true,
			history: true,
			center: true,
			width: 1920,
			height: 1080,
			// Bounds for smallest/largest possible scale to apply to content
			// minScale: .5,
			maxScale: 1,
			// slide transition
			transition: 'concave', // none/fade/slide/convex/concave/zoom
			// Factor of the display size that should remain empty around the content
			margin: 0.1,
			// shift+left click to zoom in/out element
			zoomKey: 'ctrl',
			// theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
			// transition: Reveal.getQueryHash().transition || 'default'
			// Optional reveal.js plugins
			dependencies: [
				{ src: '/PythonCourseNetIT-Slides/lib/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
				{ src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
				{ src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
				{ src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.configure({tabReplace: highlightjsTabSize}); hljs.initHighlightingOnLoad(); } },
				{ src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/zoom-js/zoom.js', async: true },
				{ src: '/PythonCourseNetIT-Slides/lib/reveal.js/plugin/notes/notes.js', async: true }
			]
		});
	</script>
</body>
</html>
